{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ“Š Blockchain Transaction Analytics - Exploratory Data Analysis\n",
        "\n",
        "This notebook performs comprehensive exploratory data analysis on blockchain transaction data stored in BigQuery.\n",
        "\n",
        "## Objectives\n",
        "1. **Data Overview**: Understand the structure and quality of raw transaction data\n",
        "2. **Transaction Analysis**: Distribution of values, gas fees, and timestamps\n",
        "3. **Wallet Behavior**: Activity patterns, transaction volumes, and counterparties\n",
        "4. **Anomaly Detection**: Identify potentially suspicious patterns\n",
        "\n",
        "## Data Sources\n",
        "- `blockchain_raw.raw_transactions` - Raw Ethereum transactions\n",
        "- `blockchain_raw.raw_wallets` - Extracted wallet information\n",
        "- `blockchain_ml.wallet_features` - ML-computed features\n",
        "- `blockchain_ml.wallet_fraud_scores` - Fraud detection scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (run once if needed)\n",
        "# !pip install google-cloud-bigquery pandas numpy matplotlib seaborn plotly db-dtypes pyarrow python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import sys\n",
        "from datetime import datetime, timedelta\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from google.cloud import bigquery\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Configure display settings\n",
        "pd.set_option('display.max_columns', 50)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.float_format', '{:.4f}'.format)\n",
        "\n",
        "# Matplotlib style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 11\n",
        "\n",
        "# Seaborn palette\n",
        "sns.set_palette('husl')\n",
        "\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Configuration\n",
        "PROJECT_ID = os.getenv('GOOGLE_CLOUD_PROJECT', 'blockchain-481614')\n",
        "RAW_DATASET = 'blockchain_raw'\n",
        "ML_DATASET = 'blockchain_ml'\n",
        "\n",
        "print(f\"Project ID: {PROJECT_ID}\")\n",
        "print(f\"Raw Dataset: {RAW_DATASET}\")\n",
        "print(f\"ML Dataset: {ML_DATASET}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize BigQuery client\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "def run_query(query: str) -> pd.DataFrame:\n",
        "    \"\"\"Execute BigQuery query and return DataFrame.\"\"\"\n",
        "    return client.query(query).to_dataframe()\n",
        "\n",
        "# Test connection\n",
        "test_query = f\"SELECT COUNT(*) as count FROM `{PROJECT_ID}.{RAW_DATASET}.raw_transactions`\"\n",
        "result = run_query(test_query)\n",
        "print(f\"âœ… BigQuery connected! Total transactions: {result['count'].iloc[0]:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Overview\n",
        "\n",
        "Let's start by understanding the structure and quality of our data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get table information\n",
        "tables_query = f\"\"\"\n",
        "SELECT \n",
        "    table_name,\n",
        "    ROUND(size_bytes / 1024 / 1024, 2) as size_mb,\n",
        "    row_count\n",
        "FROM `{PROJECT_ID}.{RAW_DATASET}.INFORMATION_SCHEMA.TABLE_STORAGE`\n",
        "ORDER BY table_name\n",
        "\"\"\"\n",
        "\n",
        "tables_info = run_query(tables_query)\n",
        "display(tables_info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample raw transactions\n",
        "sample_query = f\"\"\"\n",
        "SELECT *\n",
        "FROM `{PROJECT_ID}.{RAW_DATASET}.raw_transactions`\n",
        "LIMIT 5\n",
        "\"\"\"\n",
        "\n",
        "sample_df = run_query(sample_query)\n",
        "print(\"Raw Transactions Schema:\")\n",
        "print(sample_df.dtypes)\n",
        "print(\"\\nSample Data:\")\n",
        "display(sample_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic statistics on transactions\n",
        "stats_query = f\"\"\"\n",
        "SELECT\n",
        "    COUNT(*) as total_transactions,\n",
        "    COUNT(DISTINCT from_address) as unique_senders,\n",
        "    COUNT(DISTINCT to_address) as unique_receivers,\n",
        "    MIN(transaction_timestamp) as earliest_tx,\n",
        "    MAX(transaction_timestamp) as latest_tx,\n",
        "    SUM(CAST(value_eth AS FLOAT64)) as total_value_eth,\n",
        "    AVG(CAST(value_eth AS FLOAT64)) as avg_value_eth,\n",
        "    AVG(CAST(gas_used AS FLOAT64)) as avg_gas_used,\n",
        "    AVG(CAST(gas_price AS FLOAT64) / 1e9) as avg_gas_price_gwei\n",
        "FROM `{PROJECT_ID}.{RAW_DATASET}.raw_transactions`\n",
        "\"\"\"\n",
        "\n",
        "stats_df = run_query(stats_query)\n",
        "print(\"ðŸ“ˆ Transaction Statistics:\")\n",
        "for col in stats_df.columns:\n",
        "    val = stats_df[col].iloc[0]\n",
        "    if isinstance(val, (int, float)) and col not in ['earliest_tx', 'latest_tx']:\n",
        "        print(f\"  {col}: {val:,.2f}\")\n",
        "    else:\n",
        "        print(f\"  {col}: {val}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Transaction Value Analysis\n",
        "\n",
        "Analyze the distribution of transaction values to understand typical behavior and outliers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transaction value distribution\n",
        "value_query = f\"\"\"\n",
        "SELECT \n",
        "    CAST(value_eth AS FLOAT64) as value_eth,\n",
        "    CAST(gas_used AS INT64) as gas_used,\n",
        "    CAST(gas_price AS FLOAT64) / 1e9 as gas_price_gwei,\n",
        "    transaction_timestamp\n",
        "FROM `{PROJECT_ID}.{RAW_DATASET}.raw_transactions`\n",
        "WHERE value_eth IS NOT NULL\n",
        "\"\"\"\n",
        "\n",
        "values_df = run_query(value_query)\n",
        "print(f\"Loaded {len(values_df):,} transactions\")\n",
        "values_df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transaction value distribution visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# 1. Value distribution (log scale)\n",
        "ax1 = axes[0, 0]\n",
        "non_zero_values = values_df[values_df['value_eth'] > 0]['value_eth']\n",
        "if len(non_zero_values) > 0:\n",
        "    ax1.hist(np.log10(non_zero_values + 1e-10), bins=50, edgecolor='black', alpha=0.7, color='#3498db')\n",
        "ax1.set_xlabel('Log10(Value ETH)')\n",
        "ax1.set_ylabel('Frequency')\n",
        "ax1.set_title('Transaction Value Distribution (Log Scale)')\n",
        "if len(non_zero_values) > 0:\n",
        "    ax1.axvline(x=np.log10(non_zero_values.median()), color='red', linestyle='--', \n",
        "                label=f'Median: {non_zero_values.median():.4f} ETH')\n",
        "    ax1.legend()\n",
        "\n",
        "# 2. Zero vs Non-zero transactions\n",
        "ax2 = axes[0, 1]\n",
        "zero_count = (values_df['value_eth'] == 0).sum()\n",
        "non_zero_count = (values_df['value_eth'] > 0).sum()\n",
        "ax2.pie([zero_count, non_zero_count], labels=['Zero Value', 'Non-Zero Value'], \n",
        "        autopct='%1.1f%%', colors=['#e74c3c', '#2ecc71'], explode=(0.05, 0))\n",
        "ax2.set_title('Zero vs Non-Zero Value Transactions')\n",
        "\n",
        "# 3. Gas used distribution\n",
        "ax3 = axes[1, 0]\n",
        "gas_used = values_df['gas_used'].dropna()\n",
        "ax3.hist(gas_used, bins=50, edgecolor='black', alpha=0.7, color='#9b59b6')\n",
        "ax3.set_xlabel('Gas Used')\n",
        "ax3.set_ylabel('Frequency')\n",
        "ax3.set_title('Gas Usage Distribution')\n",
        "ax3.axvline(x=gas_used.median(), color='red', linestyle='--', label=f'Median: {gas_used.median():,.0f}')\n",
        "ax3.legend()\n",
        "\n",
        "# 4. Gas price distribution\n",
        "ax4 = axes[1, 1]\n",
        "gas_price = values_df['gas_price_gwei'].dropna()\n",
        "gas_price_filtered = gas_price[gas_price < gas_price.quantile(0.99)]\n",
        "ax4.hist(gas_price_filtered, bins=50, edgecolor='black', alpha=0.7, color='#f39c12')\n",
        "ax4.set_xlabel('Gas Price (Gwei)')\n",
        "ax4.set_ylabel('Frequency')\n",
        "ax4.set_title('Gas Price Distribution (excluding top 1%)')\n",
        "ax4.axvline(x=gas_price.median(), color='red', linestyle='--', label=f'Median: {gas_price.median():.2f} Gwei')\n",
        "ax4.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('transaction_distributions.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Value percentiles\n",
        "percentiles = [0.25, 0.5, 0.75, 0.9, 0.95, 0.99, 0.999]\n",
        "value_percentiles = values_df['value_eth'].quantile(percentiles)\n",
        "\n",
        "print(\"ðŸ“Š Transaction Value Percentiles:\")\n",
        "for p, v in zip(percentiles, value_percentiles):\n",
        "    print(f\"  {p*100:5.1f}%: {v:,.4f} ETH\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Temporal Analysis\n",
        "\n",
        "Understand how transaction activity varies over time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Daily transaction volume\n",
        "daily_query = f\"\"\"\n",
        "SELECT \n",
        "    DATE(transaction_timestamp) as tx_date,\n",
        "    COUNT(*) as tx_count,\n",
        "    SUM(CAST(value_eth AS FLOAT64)) as total_value,\n",
        "    AVG(CAST(value_eth AS FLOAT64)) as avg_value,\n",
        "    COUNT(DISTINCT from_address) as unique_senders,\n",
        "    AVG(CAST(gas_price AS FLOAT64) / 1e9) as avg_gas_gwei\n",
        "FROM `{PROJECT_ID}.{RAW_DATASET}.raw_transactions`\n",
        "GROUP BY DATE(transaction_timestamp)\n",
        "ORDER BY tx_date\n",
        "\"\"\"\n",
        "\n",
        "daily_df = run_query(daily_query)\n",
        "daily_df['tx_date'] = pd.to_datetime(daily_df['tx_date'])\n",
        "print(f\"Date range: {daily_df['tx_date'].min()} to {daily_df['tx_date'].max()}\")\n",
        "display(daily_df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time series visualization\n",
        "fig, axes = plt.subplots(3, 1, figsize=(14, 12), sharex=True)\n",
        "\n",
        "# Transaction count\n",
        "ax1 = axes[0]\n",
        "ax1.fill_between(daily_df['tx_date'], daily_df['tx_count'], alpha=0.3, color='#3498db')\n",
        "ax1.plot(daily_df['tx_date'], daily_df['tx_count'], color='#3498db', linewidth=1)\n",
        "ax1.set_ylabel('Transaction Count')\n",
        "ax1.set_title('Daily Transaction Volume Over Time')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Total value\n",
        "ax2 = axes[1]\n",
        "ax2.fill_between(daily_df['tx_date'], daily_df['total_value'], alpha=0.3, color='#2ecc71')\n",
        "ax2.plot(daily_df['tx_date'], daily_df['total_value'], color='#2ecc71', linewidth=1)\n",
        "ax2.set_ylabel('Total Value (ETH)')\n",
        "ax2.set_title('Daily Transaction Value (ETH)')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Unique senders\n",
        "ax3 = axes[2]\n",
        "ax3.fill_between(daily_df['tx_date'], daily_df['unique_senders'], alpha=0.3, color='#9b59b6')\n",
        "ax3.plot(daily_df['tx_date'], daily_df['unique_senders'], color='#9b59b6', linewidth=1)\n",
        "ax3.set_ylabel('Unique Senders')\n",
        "ax3.set_xlabel('Date')\n",
        "ax3.set_title('Daily Unique Active Senders')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('temporal_analysis.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hour of day and day of week analysis\n",
        "hourly_query = f\"\"\"\n",
        "SELECT \n",
        "    EXTRACT(HOUR FROM transaction_timestamp) as hour_of_day,\n",
        "    COUNT(*) as tx_count,\n",
        "    SUM(CAST(value_eth AS FLOAT64)) as total_value\n",
        "FROM `{PROJECT_ID}.{RAW_DATASET}.raw_transactions`\n",
        "GROUP BY hour_of_day\n",
        "ORDER BY hour_of_day\n",
        "\"\"\"\n",
        "\n",
        "hourly_df = run_query(hourly_query)\n",
        "\n",
        "dow_query = f\"\"\"\n",
        "SELECT \n",
        "    EXTRACT(DAYOFWEEK FROM transaction_timestamp) as day_of_week,\n",
        "    COUNT(*) as tx_count,\n",
        "    SUM(CAST(value_eth AS FLOAT64)) as total_value\n",
        "FROM `{PROJECT_ID}.{RAW_DATASET}.raw_transactions`\n",
        "GROUP BY day_of_week\n",
        "ORDER BY day_of_week\n",
        "\"\"\"\n",
        "\n",
        "dow_df = run_query(dow_query)\n",
        "dow_df['day_name'] = dow_df['day_of_week'].map({1: 'Sun', 2: 'Mon', 3: 'Tue', 4: 'Wed', 5: 'Thu', 6: 'Fri', 7: 'Sat'})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hour and day of week visualizations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Hour of day\n",
        "ax1 = axes[0]\n",
        "ax1.bar(hourly_df['hour_of_day'], hourly_df['tx_count'], color='#3498db', alpha=0.8)\n",
        "ax1.set_xlabel('Hour of Day (UTC)')\n",
        "ax1.set_ylabel('Transaction Count')\n",
        "ax1.set_title('Transaction Activity by Hour of Day')\n",
        "ax1.set_xticks(range(0, 24, 2))\n",
        "\n",
        "# Day of week\n",
        "ax2 = axes[1]\n",
        "colors = ['#e74c3c' if d in ['Sat', 'Sun'] else '#3498db' for d in dow_df['day_name']]\n",
        "ax2.bar(dow_df['day_name'], dow_df['tx_count'], color=colors, alpha=0.8)\n",
        "ax2.set_xlabel('Day of Week')\n",
        "ax2.set_ylabel('Transaction Count')\n",
        "ax2.set_title('Transaction Activity by Day of Week (Weekend in Red)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('time_patterns.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Wallet Activity Analysis\n",
        "\n",
        "Examine wallet behavior patterns to identify high-activity and potentially suspicious wallets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top wallets by transaction count\n",
        "top_wallets_query = f\"\"\"\n",
        "WITH wallet_activity AS (\n",
        "    SELECT \n",
        "        from_address as wallet,\n",
        "        COUNT(*) as tx_count,\n",
        "        SUM(CAST(value_eth AS FLOAT64)) as total_value,\n",
        "        'sender' as role\n",
        "    FROM `{PROJECT_ID}.{RAW_DATASET}.raw_transactions`\n",
        "    GROUP BY from_address\n",
        "    \n",
        "    UNION ALL\n",
        "    \n",
        "    SELECT \n",
        "        to_address as wallet,\n",
        "        COUNT(*) as tx_count,\n",
        "        SUM(CAST(value_eth AS FLOAT64)) as total_value,\n",
        "        'receiver' as role\n",
        "    FROM `{PROJECT_ID}.{RAW_DATASET}.raw_transactions`\n",
        "    GROUP BY to_address\n",
        ")\n",
        "SELECT \n",
        "    wallet,\n",
        "    SUM(tx_count) as total_tx,\n",
        "    SUM(total_value) as total_value,\n",
        "    SUM(CASE WHEN role = 'sender' THEN tx_count ELSE 0 END) as sent_tx,\n",
        "    SUM(CASE WHEN role = 'receiver' THEN tx_count ELSE 0 END) as received_tx\n",
        "FROM wallet_activity\n",
        "WHERE wallet IS NOT NULL\n",
        "GROUP BY wallet\n",
        "ORDER BY total_tx DESC\n",
        "LIMIT 20\n",
        "\"\"\"\n",
        "\n",
        "top_wallets_df = run_query(top_wallets_query)\n",
        "print(\"ðŸ” Top 20 Wallets by Transaction Count:\")\n",
        "display(top_wallets_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize top wallets\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Top wallets by transaction count\n",
        "ax1 = axes[0]\n",
        "top_10 = top_wallets_df.head(10)\n",
        "y_pos = range(len(top_10))\n",
        "ax1.barh(y_pos, top_10['total_tx'], color='#2ecc71', alpha=0.8)\n",
        "ax1.set_yticks(y_pos)\n",
        "ax1.set_yticklabels([f\"{w[:8]}...{w[-4:]}\" for w in top_10['wallet']])\n",
        "ax1.set_xlabel('Transaction Count')\n",
        "ax1.set_title('Top 10 Wallets by Transaction Count')\n",
        "ax1.invert_yaxis()\n",
        "\n",
        "# Top wallets by value\n",
        "ax2 = axes[1]\n",
        "top_by_value = top_wallets_df.sort_values('total_value', ascending=False).head(10)\n",
        "y_pos = range(len(top_by_value))\n",
        "ax2.barh(y_pos, top_by_value['total_value'], color='#3498db', alpha=0.8)\n",
        "ax2.set_yticks(y_pos)\n",
        "ax2.set_yticklabels([f\"{w[:8]}...{w[-4:]}\" for w in top_by_value['wallet']])\n",
        "ax2.set_xlabel('Total Value (ETH)')\n",
        "ax2.set_title('Top 10 Wallets by Total Value')\n",
        "ax2.invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('wallet_activity.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Fraud Score Analysis\n",
        "\n",
        "If the ML pipeline has been run, analyze the computed fraud scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load fraud scores (from ML pipeline)\n",
        "try:\n",
        "    scores_query = f\"\"\"\n",
        "    SELECT *\n",
        "    FROM `{PROJECT_ID}.{ML_DATASET}.wallet_fraud_scores`\n",
        "    \"\"\"\n",
        "    scores_df = run_query(scores_query)\n",
        "    print(f\"âœ… Loaded fraud scores for {len(scores_df):,} wallets\")\n",
        "    scores_available = True\n",
        "    display(scores_df.head())\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Fraud scores table not found. Run the ML pipeline first.\")\n",
        "    print(f\"   Error: {e}\")\n",
        "    scores_available = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fraud score distribution visualization\n",
        "if scores_available:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Histogram\n",
        "    ax1 = axes[0]\n",
        "    ax1.hist(scores_df['fraud_score'], bins=50, edgecolor='black', alpha=0.7, color='#e74c3c')\n",
        "    ax1.axvline(x=0.4, color='orange', linestyle='--', linewidth=2, label='Medium Risk (0.4)')\n",
        "    ax1.axvline(x=0.7, color='red', linestyle='--', linewidth=2, label='High Risk (0.7)')\n",
        "    ax1.set_xlabel('Fraud Score')\n",
        "    ax1.set_ylabel('Frequency')\n",
        "    ax1.set_title('Fraud Score Distribution')\n",
        "    ax1.legend()\n",
        "    \n",
        "    # Risk category pie chart\n",
        "    ax2 = axes[1]\n",
        "    risk_counts = scores_df['risk_category'].value_counts()\n",
        "    colors_map = {'low': '#2ecc71', 'medium': '#f39c12', 'high': '#e74c3c', 'critical': '#8e44ad'}\n",
        "    colors = [colors_map.get(c, '#95a5a6') for c in risk_counts.index]\n",
        "    ax2.pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%', colors=colors)\n",
        "    ax2.set_title('Risk Category Distribution')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('fraud_scores.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nðŸ“Š Risk Category Counts:\")\n",
        "    print(risk_counts)\n",
        "else:\n",
        "    print(\"Skipping fraud score visualization - ML pipeline not run yet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# High risk wallets analysis\n",
        "if scores_available:\n",
        "    high_risk = scores_df[scores_df['risk_category'].isin(['high', 'critical'])].sort_values('fraud_score', ascending=False)\n",
        "    print(f\"ðŸš¨ High/Critical Risk Wallets: {len(high_risk)}\")\n",
        "    display(high_risk.head(10))\n",
        "else:\n",
        "    print(\"Skipping high risk analysis - ML pipeline not run yet\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Key Insights Summary\n",
        "\n",
        "Summarize the key findings from this exploratory analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate summary insights\n",
        "print(\"=\"*60)\n",
        "print(\"ðŸ“‹ EDA SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Data overview\n",
        "print(\"\\nðŸ“Š DATA OVERVIEW:\")\n",
        "print(f\"  - Total transactions analyzed: {len(values_df):,}\")\n",
        "print(f\"  - Date range: {daily_df['tx_date'].min().date()} to {daily_df['tx_date'].max().date()}\")\n",
        "print(f\"  - Total value transferred: {values_df['value_eth'].sum():,.2f} ETH\")\n",
        "\n",
        "# Transaction patterns\n",
        "print(\"\\nðŸ’¹ TRANSACTION PATTERNS:\")\n",
        "print(f\"  - Zero-value transactions: {(values_df['value_eth'] == 0).sum():,} ({(values_df['value_eth'] == 0).mean()*100:.1f}%)\")\n",
        "print(f\"  - Median transaction value: {values_df['value_eth'].median():.4f} ETH\")\n",
        "print(f\"  - Average gas used: {values_df['gas_used'].mean():,.0f}\")\n",
        "\n",
        "# Wallet activity\n",
        "print(\"\\nðŸ‘› WALLET ACTIVITY:\")\n",
        "print(f\"  - Most active wallet: {top_wallets_df.iloc[0]['wallet'][:16]}...\")\n",
        "print(f\"  - Most active wallet txs: {top_wallets_df.iloc[0]['total_tx']:,}\")\n",
        "\n",
        "# ML insights (if available)\n",
        "if scores_available:\n",
        "    print(\"\\nðŸ¤– ML FRAUD DETECTION:\")\n",
        "    print(f\"  - Wallets scored: {len(scores_df):,}\")\n",
        "    print(f\"  - High/Critical risk: {len(high_risk):,} ({len(high_risk)/len(scores_df)*100:.1f}%)\")\n",
        "    print(f\"  - Average fraud score: {scores_df['fraud_score'].mean():.3f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“ Saved Outputs\n",
        "\n",
        "The following visualization files were generated:\n",
        "- `transaction_distributions.png` - Value and gas distributions\n",
        "- `temporal_analysis.png` - Time series of transaction activity\n",
        "- `time_patterns.png` - Hour of day and day of week patterns\n",
        "- `wallet_activity.png` - Top wallet activity\n",
        "- `fraud_scores.png` - Fraud score distributions (if ML pipeline was run)\n",
        "\n",
        "---\n",
        "\n",
        "**Next Steps:**\n",
        "1. Run the ML notebook (`02_fraud_detection_ml.ipynb`) to train fraud detection models\n",
        "2. Review high-risk wallets identified by the analysis\n",
        "3. Investigate temporal anomalies in transaction patterns\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
